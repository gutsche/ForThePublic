include({{{{../cv/leadership_experience_introduction.md}}}})

## High-Luminosity LHC

Starting in 2029, the HL-LHC will generate many times the data volume of current LHC runs. Additionally, the collisions and corresponding simulations will be significantly more complex. I have played an integral role in the community planning process, with my contributions documented in, for example, the [Roadmap for HEP Software and Computing R\&D for the 2020s](http://arxiv.org/abs/1712.06982). I also co-edited the [HEP Software Foundation Community White Paper Working Group on Data Analysis and Interpretation](http://arxiv.org/abs/1804.03983). In recognition of my expertise, I was asked in 2020 to co-lead the [Computational Frontier](https://snowmass21.org/computational/start) of the [Snowmass 2021 process](https://snowmass21.org). Due to a one-year delay in Snowmass, I resigned in 2022 to focus on higher-priority commitments, overseeing the process until a successor was appointed.

In 2023, the CMS collaboration initiated the creation of a Conceptual Design Report (CDR) for Offline & Computing, documenting the current state of HL-LHC software and computing preparations. Scheduled for publication by the end of 2025, I was invited to co-lead the computing model chapter, the core of the CDR, which includes resource needs projections and guidance on processes and workflows governing HL-LHC software and computing. The capacity planning and computing model will integrate traditional and emerging computing infrastructures into a seamless, globally integrated system.

In February 2024, the CMS Collaboration Board appointed me co-lead of the Sub-Group for Offline & Computing for HL-LHC. This sub-group is a CMS first, providing a dedicated forum to discuss and coordinate effort needs within the Offline & Computing Coordination area. Unlike detector projects, which have a projectized structure with defined institute contributions for construction and operations, Offline & Computing lacks such a structure apart from hardware contributions through WLCG. This sub-group introduces structured coordination and planning into CMS Offline & Computing efforts.

To guide HL-LHC R\&D, I co-authored a strategic plan for the U.S. CMS Software & Computing Operations Program outlining four grand challenges:

* Modernizing Physics Software and Improving Algorithms
* Building Infrastructure for Exabyte-Scale Datasets
* Transforming the Scientific Data Analysis Process
* Transitioning from R\&D to Operations

This plan is updated annually by the operations program management team and documented in the proceedings of CHEP 2023 ([arXiv:2312.00772](https://arxiv.org/abs/2312.00772)).

Under my leadership, the U.S. CMS Software & Computing Operations program established a [Research Initiative](https://uscms-software-and-computing.github.io/postdocs) to partially fund postdoctoral researchers exploring innovative solutions to the four grand challenges. This initiative has been highly successful in engaging new collaboration members and broadening the scope of potential HL-LHC R\&D solutions.

## Fermilab’s Computing Resources Evolution STrategy (CREST)

In March 2023, I created Fermilab’s Computing Resources Evolution STrategy (CREST) process. Its goal is to document a strategic plan for the evolution of Fermilab’s computing resources that addresses current experiment requirements and anticipates the future needs of DUNE and HL-LHC. CREST enables staff in the Scientific Computing Systems and Services Division (SCSS) within CSAID to collaboratively develop and own a ten-year computing resource strategy. I lead the development of the first version of this plan, which underwent broad discussion within Fermilab’s scientific community and is intended to be updated annually to reflect changes in scientific priorities and the technological landscape.

## DOE Center for Computational Excellence

In January 2020, the DOE [Center for Computational Excellence (HEP-CCE)](https://www.anl.gov/hep-cce/activities) was funded as a three-year project to enable HEP experiments such as ATLAS, CMS, DUNE, LSST, and DESI to efficiently utilize HPC facilities at leadership-class centers including Argonne, Oak Ridge, and NERSC at Lawrence Berkeley National Laboratory. I co-authored the proposal, which includes four sub-projects aimed at:

1. Investigating Parallel Portability Solutions (PPS) for developing algorithmic code once and compiling transparently across CPU and accelerator architectures;
2. Fine-Grained I/O and Storage (IOS) optimization of data structures on disk and in memory, enhancing access on large shared HPC storage systems;
3. Event Generators (EG) to optimize HEP theory code for HPC execution;
4. Complex Workflows (CW) to orchestrate workflows spanning heterogeneous hardware platforms.

I served as technical lead of the PPS sub-project and point of contact for CMS. Alongside my postdoctoral researcher Martin Kwok and staff from DOE labs including BNL, LBNL, and Fermilab, I contributed to investigate [portability solutions for HEP software](https://www.anl.gov/hep-cce/portable-parallelization-strategies), enabling CMS to make informed decisions on portability approaches for LHC Run-3.

## National and International Recognition

I am nationally and internationally recognized for my leadership in software and computing through membership in various journal editorial boards, conference committees, and mentoring programs:

include({{{{../other/other.md}}}})

and I am serving or served on the following committees:

include({{{{../cv/committees.md}}}})