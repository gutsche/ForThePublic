## Technical Experience

### Coordinator for Science Workflows and Operations: 2014 - Present

### CMS collaboration: 2005 – Present

The technical aspects of my work are closely connected to my physics research. I am involved in computing for the CMS collaboration. Computing is a significant part of the overall analysis workflow and requires intimate knowledge of the scientific process. The scales of computing resources needed for the LHC are unprecedented and analyses at the LHC depend significantly more on computing than at previous experiments. Fermilab is a leader in GRID technologies used to handle all LHC computing resources and also hosts the largest Tier-1 center of CMS.

* The CMS collaboration appointed me lead of the Data Operations Project in 2009. Using my deep involvement in analysis and my expertise in computing, I was responsible for the timely delivery of all data and MC samples for analysis, a significant contribution to the overall success of the experiment. In 2012, CMS extended my responsibilities and appointed me to lead all of the Computing Operations Project, adding the care of over 60 computing centers distributed all over the world and all central computing services of CMS.
* I was supervising the contributions of more than 60 scientists and engineers to the Computing Operations Project worldwide. The team was overseeing the readiness of all the computing facilities and monitor both central workflows and analysis and the transfers of data and MC samples between the sites.
* To help with operations of the CMS computing infrastructure, I was working with computer scientists and engineers visiting Fermilab for 1 to 2 years from Columbia, Ecuador and China. In the course of the stay at Fermilab, one of the visitors wrote a master thesis about petascale transfers for the LHC under my supervision, and defended the thesis successfully at the Chinese Academy of Sciences end of May 2013.
* I was a L2 manager in the U.S. CMS Software & Computing Program responsible for Computing Operations. In this capacity and also before, I reported regularly to the funding agencies and took part in reviews of DOE and NSF.
* I was member of the organizing committees of the International Conference on Computing in High Energy and Nuclear Physics (CHEP) 2010 and 2012 and organized parallel tracks and was editor of the proceedings. I also authored or co-authored multiple contributions to the CHEP conferences in 2010, 2012, 2013 and 2015. I was member of the organizing committee of the Meeting of the American Physical Society (APS) Division of Particles and Fields (DPF) in 2013.
* In October 2014, I was appointed Assistant Scientific Computing Division Head for Science Operations and Workflows. I am responsible for the delivery of scientific computing services to all Fermi National Accelerator Laboratory experiments including High Energy Physics experiments (e.g. CMS), Neutrino Physics experiments (e.g. NOvA, Minerva), Intensity Frontier experiments (e.g. mu2e, Muon g-2) and Astroparticle Physics experiments (e.g. DES)

I was also the lead developer of an innovative tracking algorithm that was used during the commissioning of the CMS detector and I supervised several students in the course of the project. I conducted the first software tutorials in CMS teaching the basics of analysis software and how to perform analysis on the GRID to the CMS community, using a user-friendly GRID analysis tool, of which I was one of the lead developers as well.

### ZEUS collaboration: 2001 – 2005

The upgrade of the ZEUS detector made it necessary to integrate the new and changed detector components in the event visualization solution of ZEUS. 

* I was one of the proponents and lead developers of a new object-oriented and ROOT-based event display. 
* A client-server structure allowed physicists to display events without direct access to the event store. Also online events could be displayed worldwide with very small latency during data taking.

I used my knowledge of ROOT to develop a wrapper for the Fortran based code base of ZEUS and integrated it into an analysis framework, which was used by several graduate students.
