# Scientific Interest

My current physics interests are focusing on proton-proton physics at the Large Hadron Collider (LHC) at CERN, Geneva, Switzerland. I am a member of the Compact Muon Solenoid (CMS) collaboration that built and operates one of the four detectors recording the world's highest energy proton-proton collisions. During the first running period of the LHC (Run 1: 2010-2012), I concentrated on searches for physics beyond the Standard Model (SM), the current accepted theory of matter and forces, and on precision SM measurements, both with top quarks and leptons. In LHC Run 2 (2015-2018), I am concentrating on Supersymmetry and Dark Matter searches in 13 TeV proton-proton collisions.

In LHC Run 1, I was in charge of CMS worldwide computing operations, managing teams of experts that transferred petabytes of data and executed millions of jobs on more than 65 Grid sites to process CMS data and simulations. Since 2014, I was member of the CMS Offline & Computing management team. In 2016, I was appointed deputy U.S. CMS Software and Computing operations program manager. I am involved in the day-to-day operation of this $16M operations project funding the U.S. CMS Tier-1 site at Fermilab and the 7 U.S. CMS Tier-2 sites in the country, as well as operations and development effort across the U.S. . Currently the program focusses on resource planning for the High Luminosity LHC (HL-LHC), efforts that I am leading.

I am interested in enabling science through computing and to constantly find new and efficient ways to analyze petabytes of HEP data efficiently and quickly. This touches questions of workflow management and resource provisioning on the Grid, commercial clouds and other resource types like supercomputing centers. This also poses questions on how to store, distribute and provide access to the vast amount of data collected by current and future experiments, especially the HL-LHC planned to start to take data in 2026.

I am very interested in bringing industry tools called "Big Data" tools into the HEP community for analysis. I started investigating Apache Spark and together with partners we started the [CMS Big Data Project](https://cms-big-data.github.io/). One component is the collaboration with Intel on scaling of analysis facilities to Petabytes. Fermilab recently joined [CERN openlab](https://openlab.cern/) to make this collaboration a possibility.