<p>I am a particle physicist and conduct leading edge research for New Physics Beyond the Standard Model. I have multiple years of experience in analyzing particle collisions. I am member of the CMS collaboration at the Large Hadron Collider (LHC) at <a href="https://home.cern/">CERN</a> and am looking for evidence of Dark Matter and Supersymmetry. One of my most noticeable publications is the <a href="https://doi.org/10.1016/j.physletb.2012.08.021">Observation of the Higgs Boson in 2012</a>.</p>
<p>I am a leader in scientific computing. I am an expert in object oriented software development; statistical data analysis methods, optimization and machine learning techniques; and Monte Carlo simulation techniques. I have extensive experience in planningand and operating distributed computing infrastructures (scale: 100,000 cores, 100 PB disk). I am intimately familiar with grid sites, commercial clouds and U.S. supercomputers. Recently I was part of a worldwide community planning process for the software and computing infrastructure of the High Luminosity LHC (HL-LHC, 2026). The upgraded machine and detectors will require 20 times as much resources as today. I contributed to the <a href="http://arxiv.org/abs/1712.06982">overview white paper of the community</a> and was editor of the white paper about the future of <a href="http://arxiv.org/abs/1804.03983">data analysis</a>. My interest is to use idustry technologies for petabyte scale analysis. I started the <a href="https://cms-big-data.github.io/">CMS Big Data Project</a>. One component is the collaboration with Intel on scaling of analysis facilities to Petabytes. Fermilab recently joined <a href="https://openlab.cern/">CERN openlab</a> to make this collaboration a possibility.</p>
<p>I was appointed Deputy U.S.CMS Software and Computing Operations Program manager in 2016, overseeing a budget of $16M to enable analysis of LHC particle collisions in the U.S. for the 2500 physicist strong CMS collaboration.</p>
